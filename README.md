<p align="center">
  <a href="https://t.me/codyapi"><img src="https://img.shields.io/badge/Cody%20API-2684FF?style=for-the-badge&logo=telegram&logoColor=white" alt="Cody API" /></a>
</p>

<!-- Language Switch -->
<p align="right">
  <a href="#english">üá¨üáß English</a> | <a href="#—Ä—É—Å—Å–∫–∏–π">üá∑üá∫ –†—É—Å—Å–∫–∏–π</a>
</p>

<a id="english"></a>
# Cody API

**Free, unlimited access to modern language and multimodal models via an OpenAI-compatible endpoint.**

### Contents
- [Key Features](#key-features)
- [1. Get an API Key](#1-get-an-api-key)
- [2. Quick Start](#2-quick-start-python--openai-sdk)
- [3. Endpoints](#3-endpoints)
- [4. Models](#4-models)
- [5. Rate Limits](#5-rate-limits)
- [6. Security & Privacy](#6-security--privacy)
- [7. Support](#7-support)

## Key Features
- ‚ö° **Drop-in replacement for the OpenAI SDK** ‚Äî change two lines of code.
- üÜì **Zero cost** and no hard quotas.
- üîí **Zero-retention** architecture: no request content is persisted.
- üì∑ **Multimodal**: text, image generation/editing, Text-to-Speech.
- üöÄ Constantly growing catalog of 30+ SOTA models.

---

## 1. Get an API Key
`POST https://cody.su/api/v1/get_api_key`

```python
import httpx
print(httpx.post("https://cody.su/api/v1/get_api_key").text)  # -> cody-...
```

## 2. Quick Start (Python + OpenAI SDK)

### Text
```python
from openai import OpenAI

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

resp = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "–ö–æ—Ä–æ—Ç–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è –ø—Ä–æ –∫–æ—Ç—ë–Ω–∫–∞"}],
)
print(resp.choices[0].message.content)
```

### Streaming
```python
from openai import OpenAI

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

completion = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "Write a short story about two cats named Sonya and Alice"}],
    stream=True,
)

for chunk in completion:
    if chunk.choices and chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

### Image
```python
from openai import OpenAI
import base64, pathlib

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

img = client.images.generate(
    model="gpt-image-1",
    prompt="A veterinarian listening to a baby otter‚Äôs heartbeat, children‚Äôs book style",
)
pathlib.Path("otter.png").write_bytes(base64.b64decode(img.data[0].b64_json))
```

> **Note:** The `images.generate` and `images.edit` endpoints return images **only** as base64 (`b64_json`).

### Text-to-Speech
```python
from openai import OpenAI
import base64

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

audio = client.chat.completions.create(
    model="gpt-4o-mini-audio-preview",
    modalities=["text", "audio"],
    audio={"voice": "alloy", "format": "wav"},
    messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!"}],
)
open("hello.wav", "wb").write(base64.b64decode(audio.choices[0].message.audio.data))
```

**Available voices**

`alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer`, `coral`, `verse`, `ballad`, `ash`, `sage`, `amuch`, `dan`

**Formats:** MP3, Opus, AAC, FLAC, WAV, PCM

#### Example Responses

<details>
<summary>chat.completions</summary>

```TXT
<Text answer>
```
</details>

<details>
<summary>images.generate</summary>

```json
{
  "created": 1710002222,
  "data": [
    {"b64_json": "<base64 PNG data>"}
  ]
}
```
</details>

<details>
<summary>video.generation</summary>

```json
{
  "created": 1677652288,
  "data": [
    {
      "b64_json": "..."
    }
  ]
}
```
</details>

### Video
```python
import requests, json

headers = {
    "Authorization": "Bearer cody-...",
    "Content-Type": "application/json",
}

payload = {
    "model": "wan-2.1",
    "prompt": "A cinematic shot of a futuristic city with flying cars",
    "ratio": "16:9",
    "quality": "480p",  # only 480p supported
    "duration": 4         # seconds; <= 4
}

resp = requests.post("https://cody.su/api/v1/video/generations", headers=headers, json=payload)
print(resp.json())
```

---

## 3. Endpoints

| Endpoint | Status |
|----------|--------|
| `chat.completions` | ‚úÖ |
| `images.generate`  | ‚úÖ |
| `images.edit`      | ‚úÖ |
| `video.generations` | ‚úÖ |

## 4. Models
```python
from openai import OpenAI
print(OpenAI(base_url="https://cody.su/api/v1", api_key="...").models.list())
```

#### Supported Models

**Text Generation**
```
o4-mini, o4-mini-search, o3-search, o3
gpt-4.1, gpt-4.1-mini, gpt-4.1-nano, gpt-4.1-search
gpt-4o, gpt-4o-mini, gpt-4o-mini-search-preview, gpt-4o-mini-transcribe
gemini-2.5-pro, gemini-2.5-pro-search, gemini-2.5-flash-thinking, gemini-2.5-flash, gemini-2.0-flash
claude-4.0-sonnet-thinking, claude-4.0-sonnet-thinking-search, claude-4.0-sonnet, claude-4.0-sonnet-search
deepseek-r1, deepseek-r1-search, deepseek-v3
grok-3-mini, kimi-k2, sonar
llama-4-maverick, llama-4-scout
qwq-32b, qwen-3-235b, qwen-3-235b-a22b, qwen2.5-coder
minimax-m1-40k
phi-4-mini
```

**Image Generation / Editing**
```
gpt-image-1
imagen-4, imagen-3
sana-1.5, sana-1.5-flash
flux.1-kontext, flux.1-dev, flux.1-schnell-v2, flux.1-schnell
```

**Audio (TTS / ASR)**
```
gpt-4o-mini-audio-preview
```

**Video**
```
wan-2.1
```

## 5. Rate Limits
- 20 requests per minute
- 5 requests per second  
Updates will be announced in our [Telegram channel](https://t.me/codyapi).

## 6. Security & Privacy
- Zero-retention: all data lives only in RAM.
- No request/response logging.

## 7. Support
- **Email:** vvirtr@gmail.com
- **Telegram:** [@vvirtr](https://t.me/vvirtr)
- **Channel:** [t.me/codyapi](https://t.me/codyapi)

---

<a id="—Ä—É—Å—Å–∫–∏–π"></a>
# Cody API

**–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –±–µ–∑–ª–∏–º–∏—Ç–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–≤—ã–º –∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º –º–æ–¥–µ–ª—è–º —á–µ—Ä–µ–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å OpenAI endpoint.**

### –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
- [–ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏](#–∫–ª—é—á–µ–≤—ã–µ-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏)
- [1. –ü–æ–ª—É—á–∏—Ç—å API-–∫–ª—é—á](#1-–ø–æ–ª—É—á–∏—Ç—å-api-–∫–ª—é—á)
- [2. –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç](#2-–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç-python--openai-sdk)
- [3. –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã](#3-—ç–Ω–¥–ø–æ–∏–Ω—Ç—ã)
- [4. –ú–æ–¥–µ–ª–∏](#4-–º–æ–¥–µ–ª–∏)
- [5. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è](#5-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
- [6. –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å](#6-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å-–∏-–∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å)
- [7. –ü–æ–¥–¥–µ—Ä–∂–∫–∞](#7-–ø–æ–¥–¥–µ—Ä–∂–∫–∞)

## –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
- ‚ö° **Drop-in –∑–∞–º–µ–Ω–∞ OpenAI SDK** ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞.
- üÜì **–ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ**, –±–µ–∑ –∂—ë—Å—Ç–∫–∏—Ö –∫–≤–æ—Ç.
- üîí **Zero-retention** –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
- üì∑ **–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å**: —Ç–µ–∫—Å—Ç, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è/—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, TTS.
- üöÄ –ö–∞—Ç–∞–ª–æ–≥ –∏–∑ 30+ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö SOTA –º–æ–¥–µ–ª–µ–π.

---

## 1. –ü–æ–ª—É—á–∏—Ç—å API-–∫–ª—é—á
`POST https://cody.su/api/v1/get_api_key`

```python
import httpx
print(httpx.post("https://cody.su/api/v1/get_api_key").text)  # -> cody-...
```

## 2. –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (Python + OpenAI SDK)

### –¢–µ–∫—Å—Ç
```python
from openai import OpenAI

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

resp = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "–ö–æ—Ä–æ—Ç–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è –ø—Ä–æ –∫–æ—Ç—ë–Ω–∫–∞"}],
)
print(resp.choices[0].message.content)
```

### –°—Ç—Ä–∏–º–∏–Ω–≥
```python
from openai import OpenAI

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

completion = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç, –Ω–∞–ø–∏—à–∏ –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ 2—Ö –∫–æ—à–µ–∫: –°–æ–Ω—é –∏ –ê–ª–∏—Å—É"}],
    stream=True,
)

for chunk in completion:
    if chunk.choices and chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

### –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
```python
from openai import OpenAI
import base64, pathlib

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

img = client.images.generate(
    model="gpt-image-1",
    prompt="–í–µ—Ç–µ—Ä–∏–Ω–∞—Ä —Å–ª—É—à–∞–µ—Ç —Å–µ—Ä–¥—Ü–µ –¥–µ—Ç—ë–Ω—ã—à–∞ –≤—ã–¥—Ä—ã, —Å—Ç–∏–ª—å –¥–µ—Ç—Å–∫–æ–π –∫–Ω–∏–≥–∏",
)
pathlib.Path("otter.png").write_bytes(base64.b64decode(img.data[0].b64_json))
```

> **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã `images.generate` –∏ `images.edit` –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è **—Ç–æ–ª—å–∫–æ** –≤ Base64 (`b64_json`).

### –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏
```python
from openai import OpenAI
import base64

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

audio = client.chat.completions.create(
    model="gpt-4o-mini-audio-preview",
    modalities=["text", "audio"],
    audio={"voice": "alloy", "format": "wav"},
    messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!"}],
)
open("hello.wav", "wb").write_bytes(base64.b64decode(audio.choices[0].message.audio.data))
```

**–î–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ–ª–æ—Å–∞**

`alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer`, `coral`, `verse`, `ballad`, `ash`, `sage`, `amuch`, `dan`

**Formats:** MP3, Opus, AAC, FLAC, WAV, PCM

#### –ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤

<details>
<summary>chat.completions</summary>

```TXT
<Text answer>
```
</details>

<details>
<summary>images.generate</summary>

```json
{
  "created": 1710002222,
  "data": [
    {"b64_json": "<base64 PNG data>"}
  ]
}
```
</details>

<details>
<summary>video.generation</summary>

```json
{
  "created": 1677652288,
  "data": [
    {
      "b64_json": "..."
    }
  ]
}
```
</details>

### –í–∏–¥–µ–æ
```python
import requests, json

headers = {
    "Authorization": "Bearer cody-...",
    "Content-Type": "application/json",
}

payload = {
    "model": "wan-2.1",
    "prompt": "–ö–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–Ω—ã–π –∫–∞–¥—Ä —Ñ—É—Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥–æ—Ä–æ–¥–∞ —Å –ª–µ—Ç–∞—é—â–∏–º–∏ –º–∞—à–∏–Ω–∞–º–∏",
    "ratio": "16:9",
    "quality": "480p",  # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ 480p
    "duration": 4         # —Å–µ–∫—É–Ω–¥; <= 4
}

resp = requests.post("https://cody.su/api/v1/video/generations", headers=headers, json=payload)
print(resp.json())
```

---

## 3. –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã

| Endpoint | –°—Ç–∞—Ç—É—Å |
|----------|--------|
| `chat.completions` | ‚úÖ |
| `images.generate`  | ‚úÖ |
| `images.edit`      | ‚úÖ |
| `video.generations` | ‚úÖ |

## 4. –ú–æ–¥–µ–ª–∏
```python
from openai import OpenAI
print(OpenAI(base_url="https://cody.su/api/v1", api_key="...").models.list())
```

#### –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏

**–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞**
```
o4-mini, o4-mini-search, o3-search, o3
gpt-4.1, gpt-4.1-mini, gpt-4.1-nano, gpt-4.1-search
gpt-4o, gpt-4o-mini, gpt-4o-mini-search-preview, gpt-4o-mini-transcribe
gemini-2.5-pro, gemini-2.5-pro-search, gemini-2.5-flash-thinking, gemini-2.5-flash, gemini-2.0-flash
claude-4.0-sonnet-thinking, claude-4.0-sonnet-thinking-search, claude-4.0-sonnet, claude-4.0-sonnet-search
deepseek-r1, deepseek-r1-search, deepseek-v3
grok-3-mini, kimi-k2, sonar
llama-4-maverick, llama-4-scout
qwq-32b, qwen-3-235b, qwen-3-235b-a22b, qwen2.5-coder
minimax-m1-40k
phi-4-mini
```

**–ì–µ–Ω–µ—Ä–∞—Ü–∏—è / —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**
```
gpt-image-1
imagen-4, imagen-3
sana-1.5, sana-1.5-flash
flux.1-kontext, flux.1-dev, flux.1-schnell-v2, flux.1-schnell
```

**–ê—É–¥–∏–æ (TTS / ASR)**
```
gpt-4o-mini-audio-preview
```

**–í–∏–¥–µ–æ**
```
wan-2.1
```

## 5. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- 20 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É
- 5 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É  
–û–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É–±–ª–∏–∫—É—é—Ç—Å—è –≤ [Telegram-–∫–∞–Ω–∞–ª–µ](https://t.me/codyapi).

## 6. –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å
- Zero-retention: –¥–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ RAM.
- –ó–∞–ø—Ä–æ—Å—ã/–æ—Ç–≤–µ—Ç—ã –Ω–µ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è.

## 7. –ü–æ–¥–¥–µ—Ä–∂–∫–∞
- **Email:** vvirtr@gmail.com
- **Telegram:** [@vvirtr](https://t.me/vvirtr)
- **–ö–∞–Ω–∞–ª:** [t.me/codyapi](https://t.me/codyapi)
