<p align="center">
  <a href="https://t.me/codyapi"><img src="https://img.shields.io/badge/Cody%20API-2684FF?style=for-the-badge&logo=telegram&logoColor=white" alt="Cody API" /></a>
</p>

<!-- Language Switch -->
<p align="right">
  <a href="#english">üá¨üáß English</a> | <a href="#—Ä—É—Å—Å–∫–∏–π">üá∑üá∫ –†—É—Å—Å–∫–∏–π</a>
</p>

<a id="english"></a>
# Cody API

**Free, unlimited access to modern language and multimodal models via an OpenAI-compatible endpoint.**

### Contents
- [Key Features](#key-features)
- [1. Get an API Key](#1-get-an-api-key)
- [2. Quick Start](#2-quick-start-python--openai-sdk)
- [3. Endpoints](#3-endpoints)
- [4. Models](#4-models)
- [5. Rate Limits](#5-rate-limits)
- [6. Security & Privacy](#6-security--privacy)
- [7. Support](#7-support)

## Key Features
- ‚ö° **Drop-in replacement for the OpenAI SDK** ‚Äî change two lines of code.
- üÜì **Zero cost** and no hard quotas.
- üîí **Zero-retention** architecture: no request content is persisted.
- üì∑ **Multimodal**: text, image generation/editing, Text-to-Speech.
- üöÄ Constantly growing catalog of 400+ SOTA models.

---

## 1. Get an API Key
`POST https://cody.su/api/v1/get_api_key`

```python
import httpx
print(httpx.post("https://cody.su/api/v1/get_api_key").text)  # -> cody-...
```

## 2. Quick Start (Python + OpenAI SDK)

### Text
```python
from openai import OpenAI

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

resp = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "–ö–æ—Ä–æ—Ç–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è –ø—Ä–æ –∫–æ—Ç—ë–Ω–∫–∞"}],
)
print(resp.choices[0].message.content)
```

### Streaming
```python
from openai import OpenAI

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

completion = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "Write a short story about two cats named Sonya and Alice"}],
    stream=True,
)

for chunk in completion:
    if chunk.choices and chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

### Image
```python
from openai import OpenAI
import base64, pathlib

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

img = client.images.generate(
    model="gpt-image-1",
    prompt="A veterinarian listening to a baby otter‚Äôs heartbeat, children‚Äôs book style",
)
pathlib.Path("otter.png").write_bytes(base64.b64decode(img.data[0].b64_json))
```

### Image Edit
```python
from openai import OpenAI, base64, pathlib

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

edited = client.images.edit(
    model="gpt-image-1",
    prompt="Add sunglasses",
    image=open("otter.png", "rb"),
    mask=open("mask.png", "rb"),
)
pathlib.Path("otter_edit.png").write_bytes(base64.b64decode(edited.data[0].b64_json))
```

> **Note:** The `images.generate` and `images.edit` endpoints return images **only** as base64 (`b64_json`).

### Video
```python
import requests, json

headers = {
    "Authorization": "Bearer cody-...",
    "Content-Type": "application/json",
}

payload = {
    "model": "wan-2.1",
    "prompt": "A cinematic shot of a futuristic city with flying cars",
    "ratio": "16:9",
    "quality": "480p",  # only 480p supported
    "duration": 4         # seconds; <= 4
}

resp = requests.post("https://cody.su/api/v1/video/generations", headers=headers, json=payload)
print(resp.json())
```

### Text-to-Speech
```python
from openai import OpenAI
import base64

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

audio = client.chat.completions.create(
    model="gpt-4o-mini-audio-preview",
    modalities=["text", "audio"],
    audio={"voice": "alloy", "format": "wav"},
    messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!"}],
)
open("hello.wav", "wb").write(base64.b64decode(audio.choices[0].message.audio.data))
```

**Available voices**

`alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer`, `coral`, `verse`, `ballad`, `ash`, `sage`, `amuch`, `dan`

**Formats:** MP3, Opus, AAC, FLAC, WAV, PCM

#### Example Responses

<details>
<summary>chat.completions</summary>

```TXT
<Text answer>
```
</details>

<details>
<summary>images.generate</summary>

```json
{
  "created": 1710002222,
  "data": [
    {"b64_json": "<base64 PNG data>"}
  ]
}
```
</details>

<details>
<summary>images.edit</summary>

```json
{
  "created": 1710002223,
  "data": [
    {
      "b64_json": "<base64 PNG data>"
    }
  ]
}
```
</details>

<details>
<summary>video.generation</summary>

```json
{
  "created": 1677652288,
  "data": [
    {
      "b64_json": "<base64 Video data>"
    }
  ]
}
```
</details>

---

## 3. Endpoints

| Endpoint | Status |
|----------|--------|
| `chat.completions` | ‚úÖ |
| `images.generate`  | ‚úÖ |
| `images.edit`      | ‚úÖ |
| `video.generations` | ‚úÖ |

## 4. Models
```python
from openai import OpenAI
print(OpenAI(base_url="https://cody.su/api/v1", api_key="...").models.list())
```

#### Supported Models  
A concise subset is shown below. See the full catalog in [MODELS.md](./MODELS.md).

## 5. Rate Limits
- 20 requests per minute
- 5 requests per second  
Updates will be announced in our [Telegram channel](https://t.me/codyapi).

## 6. Security & Privacy
- Zero-retention: all data lives only in RAM.
- No request/response logging.

## 7. Support
- **Email:** vvirtr@gmail.com
- **Telegram:** [@vvirtr](https://t.me/vvirtr)
- **Channel:** [t.me/codyapi](https://t.me/codyapi)

---

<a id="—Ä—É—Å—Å–∫–∏–π"></a>
# Cody API

**–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –±–µ–∑–ª–∏–º–∏—Ç–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–≤—ã–º –∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º –º–æ–¥–µ–ª—è–º —á–µ—Ä–µ–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å OpenAI endpoint.**

### –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
- [–ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏](#–∫–ª—é—á–µ–≤—ã–µ-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏)
- [1. –ü–æ–ª—É—á–∏—Ç—å API-–∫–ª—é—á](#1-–ø–æ–ª—É—á–∏—Ç—å-api-–∫–ª—é—á)
- [2. –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç](#2-–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç-python--openai-sdk)
- [3. –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã](#3-—ç–Ω–¥–ø–æ–∏–Ω—Ç—ã)
- [4. –ú–æ–¥–µ–ª–∏](#4-–º–æ–¥–µ–ª–∏)
- [5. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è](#5-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
- [6. –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å](#6-–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å-–∏-–∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å)
- [7. –ü–æ–¥–¥–µ—Ä–∂–∫–∞](#7-–ø–æ–¥–¥–µ—Ä–∂–∫–∞)

## –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
- ‚ö° **Drop-in –∑–∞–º–µ–Ω–∞ OpenAI SDK** ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞.
- üÜì **–ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ**, –±–µ–∑ –∂—ë—Å—Ç–∫–∏—Ö –∫–≤–æ—Ç.
- üîí **Zero-retention** –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
- üì∑ **–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å**: —Ç–µ–∫—Å—Ç, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è/—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, TTS.
- üöÄ –ö–∞—Ç–∞–ª–æ–≥ –∏–∑ 400+ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö SOTA –º–æ–¥–µ–ª–µ–π.

---

## 1. –ü–æ–ª—É—á–∏—Ç—å API-–∫–ª—é—á
`POST https://cody.su/api/v1/get_api_key`

```python
import httpx
print(httpx.post("https://cody.su/api/v1/get_api_key").text)  # -> cody-...
```

## 2. –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (Python + OpenAI SDK)

### –¢–µ–∫—Å—Ç
```python
from openai import OpenAI

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

resp = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "–ö–æ—Ä–æ—Ç–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è –ø—Ä–æ –∫–æ—Ç—ë–Ω–∫–∞"}],
)
print(resp.choices[0].message.content)
```

### –°—Ç—Ä–∏–º–∏–Ω–≥
```python
from openai import OpenAI

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

completion = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç, –Ω–∞–ø–∏—à–∏ –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ 2—Ö –∫–æ—à–µ–∫: –°–æ–Ω—é –∏ –ê–ª–∏—Å—É"}],
    stream=True,
)

for chunk in completion:
    if chunk.choices and chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

### –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
```python
from openai import OpenAI
import base64, pathlib

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

img = client.images.generate(
    model="gpt-image-1",
    prompt="–í–µ—Ç–µ—Ä–∏–Ω–∞—Ä —Å–ª—É—à–∞–µ—Ç —Å–µ—Ä–¥—Ü–µ –¥–µ—Ç—ë–Ω—ã—à–∞ –≤—ã–¥—Ä—ã, —Å—Ç–∏–ª—å –¥–µ—Ç—Å–∫–æ–π –∫–Ω–∏–≥–∏",
)
pathlib.Path("otter.png").write_bytes(base64.b64decode(img.data[0].b64_json))
```

### –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
```python
from openai import OpenAI
import base64, pathlib

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

edited = client.images.edit(
    model="gpt-image-1",
    prompt="–î–æ–±–∞–≤—å —Å–æ–ª–Ω–µ—á–Ω—ã–µ –æ—á–∫–∏",
    image=open("otter.png", "rb"),
    mask=open("mask.png", "rb"),
)
pathlib.Path("otter_edit.png").write_bytes(base64.b64decode(edited.data[0].b64_json))
```
> **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã `images.generate` –∏ `images.edit` –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è **—Ç–æ–ª—å–∫–æ** –≤ Base64 (`b64_json`).

### –í–∏–¥–µ–æ
```python
import requests, json

headers = {
    "Authorization": "Bearer cody-...",
    "Content-Type": "application/json",
}

payload = {
    "model": "wan-2.1",
    "prompt": "–ö–∏–Ω–µ–º–∞—Ç–æ–≥—Ä–∞—Ñ–∏—á–Ω—ã–π –∫–∞–¥—Ä —Ñ—É—Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥–æ—Ä–æ–¥–∞ —Å –ª–µ—Ç–∞—é—â–∏–º–∏ –º–∞—à–∏–Ω–∞–º–∏",
    "ratio": "16:9",
    "quality": "480p",  # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ 480p
    "duration": 4         # —Å–µ–∫—É–Ω–¥; <= 4
}

resp = requests.post("https://cody.su/api/v1/video/generations", headers=headers, json=payload)
print(resp.json())
```

### –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏
```python
from openai import OpenAI
import base64

client = OpenAI(base_url="https://cody.su/api/v1", api_key="cody-...")

audio = client.chat.completions.create(
    model="gpt-4o-mini-audio-preview",
    modalities=["text", "audio"],
    audio={"voice": "alloy", "format": "wav"},
    messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!"}],
)
open("hello.wav", "wb").write_bytes(base64.b64decode(audio.choices[0].message.audio.data))
```

**–î–æ—Å—Ç—É–ø–Ω—ã–µ –≥–æ–ª–æ—Å–∞**

`alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer`, `coral`, `verse`, `ballad`, `ash`, `sage`, `amuch`, `dan`

**Formats:** MP3, Opus, AAC, FLAC, WAV, PCM

#### –ü—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤

<details>
<summary>chat.completions</summary>

```TXT
<Text answer>
```
</details>

<details>
<summary>images.generate</summary>

```json
{
  "created": 1710002222,
  "data": [
    {"b64_json": "<base64 PNG data>"}
  ]
}
```
</details>

<details>
<summary>images.edit</summary>

```json
{
  "created": 1710002223,
  "data": [
    {"b64_json": "<base64 PNG data>"}
  ]
}
```
</details>

<details>
<summary>video.generation</summary>

```json
{
  "created": 1677652288,
  "data": [
    {
      "b64_json": "<base64 Video data>"
    }
  ]
}
```
</details>

---

## 3. –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã

| Endpoint | –°—Ç–∞—Ç—É—Å |
|----------|--------|
| `chat.completions` | ‚úÖ |
| `images.generate`  | ‚úÖ |
| `images.edit`      | ‚úÖ |
| `video.generations` | ‚úÖ |

## 4. –ú–æ–¥–µ–ª–∏
```python
from openai import OpenAI
print(OpenAI(base_url="https://cody.su/api/v1", api_key="...").models.list())
```

#### –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏  
–ü–æ–ª–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–º. –≤ [MODELS.md](./MODELS.md).


## 5. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- 20 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É
- 5 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É  
–û–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É–±–ª–∏–∫—É—é—Ç—Å—è –≤ [Telegram-–∫–∞–Ω–∞–ª–µ](https://t.me/codyapi).

## 6. –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å
- Zero-retention: –¥–∞–Ω–Ω—ã–µ —Ö—Ä–∞–Ω—è—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ RAM.
- –ó–∞–ø—Ä–æ—Å—ã/–æ—Ç–≤–µ—Ç—ã –Ω–µ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è.

## 7. –ü–æ–¥–¥–µ—Ä–∂–∫–∞
- **Email:** vvirtr@gmail.com
- **Telegram:** [@vvirtr](https://t.me/vvirtr)
- **–ö–∞–Ω–∞–ª:** [t.me/codyapi](https://t.me/codyapi)
